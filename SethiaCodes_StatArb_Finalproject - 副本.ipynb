{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "from sklearn.linear_model import LinearRegression as lm \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import statsmodels.api as sm\n",
    "import datetime as date\n",
    "import matplotlib.pyplot as plt\n",
    "from pykalman import KalmanFilter\n",
    "from scipy.stats import t,ttest_ind,norm,iqr\n",
    "from sklearn.metrics import r2_score\n",
    "import pyfolio as pf\n",
    "from numpy.linalg import inv\n",
    "%matplotlib inline\n",
    "\n",
    "# Ignoring Warnings produced\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of Multivariate and Static Regression and Kalman Filters\n",
    "\n",
    "Implementation is done using functions in 'sklearn' and 'pykalman' libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def regression(xdata,ydata):\n",
    "    flag=0\n",
    "    if isinstance(xdata, pd.DataFrame):\n",
    "        flag=1\n",
    "    xdat=pd.DataFrame(xdata)\n",
    "    xdat['b0']=1\n",
    "    xdat=xdat.values\n",
    "    ydata=ydata.values\n",
    "    n= np.dot(xdat.T,xdat)\n",
    "    beta = np.dot(np.dot(inv(n),xdat.T),ydata) \n",
    "    coef=beta[0:-1]\n",
    "    intercept=beta[-1]\n",
    "    \n",
    "    if flag == 1:\n",
    "        xdata.drop(labels='b0',axis=1,inplace=True)\n",
    "        temp=coef*xdata\n",
    "        residuals=ydata-temp.sum(axis=1)-intercept\n",
    "    else:\n",
    "        coef=coef[0]\n",
    "        residuals=ydata-coef*xdata-intercept\n",
    "    \n",
    "    \n",
    "    return coef,intercept,residuals.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Producing Dynamic Estimates of Regression Parameters\n",
    "def dynamic_regression(xdata,ydata,delta=1e-4):\n",
    "    observation_matrix=np.vstack([xdata,np.ones(xdata.shape[0])]).T[:, np.newaxis]\n",
    "    \n",
    "    #Delta coefficient will determine the frequency of rebalancing estimates\n",
    "    trans_cov = delta / (1 - delta) * np.eye(2)\n",
    "\n",
    "    kf = KalmanFilter(n_dim_obs=1, n_dim_state=2,\n",
    "                  initial_state_mean=np.zeros(2),\n",
    "                  initial_state_covariance=np.ones((2, 2)),\n",
    "                  transition_matrices=np.eye(2),\n",
    "                  observation_matrices=observation_matrix,\n",
    "                  observation_covariance=1.0,\n",
    "                  transition_covariance=trans_cov)\n",
    "\n",
    "    state_means, state_covs = kf.filter(ydata)\n",
    "\n",
    "    slope=state_means[:,0]\n",
    "    intercept=state_means[:,1]\n",
    "\n",
    "    return slope,intercept,ydata.values-slope*xdata.values-intercept\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Engle - Granger Process and Cointegration Test\n",
    "\n",
    "The Engle - Granger process is implemented and testing for cointegration pairs in done. This is done using test for stationarity of the residuals. Stationarity test used is ADF test, with null hypothesis that a unit root exists in the residuals. If the null hypothesis is rejected and no unit root exists, residuals are stationary and then the significance of cointegration is tested for. The significance is testing using the results from the ECM model. The robustness of the parameters and the cointegration is then tested over time. \n",
    "\n",
    "Engle-Granger过程被用于实施和测试协整对。测试协整对的方法是通过对残差进行平稳性检验。平稳性检验使用的是ADF检验，其零假设是残差中存在单位根。如果零假设被拒绝，即不存在单位根，那么残差就是平稳的，然后可以对协整的显著性进行测试。协整的显著性测试使用的是误差修正模型（ECM）的结果。然后，可以对参数和协整的稳健性进行随时间的测试。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of Augmented Dickey Fuller Test \n",
    "\n",
    "Auto Regressing the residuals with a lag of 1 and a lagged delta. The t-statistic of the coefficient of the lagged delta will then be checked against the ADF critical values to check for unit root. If the null hypothesis is rejected, no unit root exists and the residuals are stationary otherwise the pair is rejected. A test for significance of cointegration can then be made. \n",
    "\n",
    "对残差进行自回归，使用1个滞后期和滞后差分。然后，将滞后差分的系数的t统计量与ADF临界值进行比较，以检查是否存在单位根。如果零假设被拒绝，则不存在单位根，残差是平稳的；否则，将拒绝该对。然后可以进行协整的显著性测试。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_stationarity(residuals):\n",
    "    # Augmenting 1-period lag and 1 period lag of delta of lag into the dataset\n",
    "    adf_data=pd.DataFrame(residuals)\n",
    "    adf_data.columns=['y']\n",
    "    adf_data['drift_constant']=1\n",
    "    adf_data['y-1']=adf_data['y'].shift(1)\n",
    "    adf_data.dropna(inplace=True)\n",
    "    adf_data['deltay1']=adf_data['y']-adf_data['y-1']\n",
    "    adf_data['deltay-1']=adf_data['deltay1'].shift(1)\n",
    "    adf_data.dropna(inplace=True)\n",
    "    target_y=pd.DataFrame(adf_data['deltay1'],columns=['deltay1'])\n",
    "    adf_data.drop(['y','deltay1'],axis=1,inplace=True)\n",
    "    \n",
    "    #Auto regressing the residuals with lag1, drift constant and lagged 1 delta (delta_et-1)\n",
    "    adf_regressor_model=sm.OLS(target_y,adf_data)\n",
    "    adf_regressor=adf_regressor_model.fit()\n",
    "    \n",
    "    # Returning the results\n",
    "    return adf_regressor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of Error Correction Model\n",
    "\n",
    "Testing the significance of the coefficient of lagged residual using its t-statistic. The cointegration is relevant only if the significance test is passed at the specified confidence interval\n",
    "\n",
    "使用滞后残差的系数的t统计量来测试其显著性。只有在指定的置信区间内通过显著性测试时，协整才是相关的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_significance(xdata,ydata,residuals):\n",
    "    # Augmenting 1-period lagged residual into the dataset\n",
    "    residuals=pd.DataFrame(residuals)\n",
    "    ecm_data=pd.DataFrame(residuals.shift(1))\n",
    "    ecm_data.columns=['et-1']\n",
    "    ecm_data['y1']=ydata.values\n",
    "    ecm_data['y2']=xdata.values\n",
    "    ecm_data['deltay']=ecm_data['y1']-ecm_data['y1'].shift(1)\n",
    "    ecm_data['deltax']=ecm_data['y2']-ecm_data['y2'].shift(1)\n",
    "    ecm_data.dropna(inplace=True)\n",
    "\n",
    "    \n",
    "    target_y=pd.DataFrame(ecm_data['deltay'])\n",
    "    ecm_data.drop(['y1','y2','deltay'],axis=1,inplace=True)\n",
    "    \n",
    "    \n",
    "    # Regressing the delta y against the delta x and the 1 period lagged residuals \n",
    "    ecm_regressor1_model=sm.OLS(target_y,ecm_data)\n",
    "    ecm_regressor1=ecm_regressor1_model.fit()\n",
    "    \n",
    "    # Returning the results of the regression\n",
    "    return ecm_regressor1  \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the the results of the regression from ADF and ECM functions\n",
    "\n",
    "The regression results returned are tested against the ADF and t-statistic critical value for the specified confidence level. The result is then interpreted and the leading variable is found\n",
    "\n",
    "回归结果与指定置信水平下的ADF和t统计量临界值进行测试。然后解释结果，并找到领先变量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cointegration_test(xdata,ydata,stat_value_ci,sig_value_ci,s1,s2):\n",
    "    \n",
    "    \n",
    "    adf_critical_values1={'0.99':-3.46, '0.95':-2.88,'0.9':-2.57}\n",
    "    adf_critical_values2={'0.99':-3.44,'0.95':-2.87,'0.9':-2.57}\n",
    "    adf_critical_values3={'0.99':-3.43,'0.95':-2.86,'0.9':-2.57}\n",
    "    \n",
    "    coef1,intercept1,residuals1=regression(xdata,ydata)\n",
    "    coef2,intercept2,residuals2=regression(ydata,xdata)\n",
    "    flag=0 \n",
    "    flag1=0\n",
    "    \n",
    "    stat_test=test_stationarity(residuals1)\n",
    "    print(\"\\nThe following is the result of the Augmented Dickey Fuller test\")\n",
    "    print(stat_test.summary())\n",
    "    if len(residuals1) > 500:\n",
    "        if abs(stat_test.tvalues['y-1']) > abs(adf_critical_values3[str(stat_value_ci)]):\n",
    "            print(\"\\nThe t-statistic value of the unit root coefficient is {} and the null hypothesis of a unit root is rejected. Hence, no unit root exists and residuals are stationary\".format(stat_test.tvalues['y-1']))\n",
    "            #pass\n",
    "        else:\n",
    "            print(\"\\nThe t-statistic value of the unit root coefficient is {} and the null hypothesis of a unit root is accepted. Hence, a unit root exists and residuals are not stationary and Error Correction Model is not checked for\".format(stat_test.tvalues['y-1']))\n",
    "            return -1\n",
    "            \n",
    "    elif len(residuals1) > 250:\n",
    "        if abs(stat_test.tvalues['y-1']) > abs(adf_critical_values2[str(stat_value_ci)]):\n",
    "            print(\"\\nThe t-statistic value of the unit root coefficient is {} and the null hypothesis of a unit root is rejected. Hence, no unit root exists and residuals are stationary\".format(stat_test.tvalues['y-1']))\n",
    "            #pass\n",
    "        else:\n",
    "            print(\"\\nThe t-statistic value of the unit root coefficient is {} and the null hypothesis of a unit root is accepted. Hence, a unit root exists and residuals are not stationary and Error Correction Model is not checked for\".format(stat_test.tvalues['y-1']))\n",
    "            #return -1\n",
    "        \n",
    "    elif len(residuals1) > 100:\n",
    "        if abs(stat_test.tvalues['y-1']) > abs(adf_critical_values1[str(stat_value_ci)]):\n",
    "            print(\"\\nThe t-statistic value of the unit root coefficient is {} and the null hypothesis of a unit root is rejected. Hence, no unit root exists and residuals are stationary\".format(stat_test.tvalues['y-1']))\n",
    "            #pass\n",
    "        else:\n",
    "            print(\"\\nThe t-statistic value of the unit root coefficient is {} and the null hypothesis of a unit root is accepted. Hence, a unit root exists and residuals are not stationary and Error Correction Model is not checked for\".format(stat_test.tvalues['y-1']))  \n",
    "            return -1\n",
    "            \n",
    "    \n",
    "    sig_1=test_significance(xdata,ydata,residuals1)\n",
    "    sig_2=test_significance(ydata,xdata,residuals2)\n",
    "        \n",
    "        \n",
    "    print(\"\\nThe following is the regression result of the Error Correction model when {} is the independent and {} is the dependent variable\".format(s1,s2))\n",
    "    print(sig_1.summary())\n",
    "    \n",
    "    critical_value=abs(t.ppf(sig_value_ci+0.5*(1-sig_value_ci),len(residuals1)))\n",
    "    if abs(sig_1.tvalues['et-1']) > critical_value:\n",
    "        print(\"\\nThe t-statistic value of the lagged residual coefficient in the error correction model is {} against a critical value of {} and the null hypothesis of the coefficient not being significant is rejected. Hence, cointegration is significant\".format(sig_1.tvalues['et-1'],critical_value))\n",
    "        \n",
    "    else:\n",
    "        print(\"\\nThe t-statistic value of the lagged residual coefficient in the error correction model is {} against a critical value of {} and the null hypothesis of the coefficient not being significant is accepted. Hence, cointegration is not significant\".format(sig_1.tvalues['et-1'],critical_value))\n",
    "        flag1+=1        \n",
    "       \n",
    "    print(\"\\nThe following is the regression result of the Error Correction model when {} is the independent and {} is the dependent variable\".format(s2,s1))\n",
    "    print(sig_2.summary())\n",
    "    critical_value=abs(t.ppf(sig_value_ci+0.5*(1-sig_value_ci),len(residuals2)))\n",
    "    if abs(sig_2.tvalues['et-1']) > critical_value:\n",
    "        print(\"\\nThe t-statistic value of the lagged residual coefficient in the error correction model is {} against a critical value of {} and the null hypothesis of the coefficient not being significant is rejected. Hence, cointegration is significant\".format(sig_2.tvalues['et-1'],critical_value))   \n",
    "    else:\n",
    "        print(\"\\nThe t-statistic value of the lagged residual coefficient in the error correction model is {} against a critical value of {} and the null hypothesis of the coefficient not being significant is accepted. Hence, cointegration is not significant\".format(sig_2.tvalues['et-1'],critical_value))\n",
    "        flag1+=1\n",
    "\n",
    "    if flag1 == 2:\n",
    "        return -2\n",
    "    \n",
    "    if abs(sig_1.tvalues['et-1']) < abs(sig_2.tvalues['et-1']):\n",
    "        print(\"\\nFor the cointegration problem, the independent variable in regression between the asset classes is {} and the dependent variable is {}\".format(s1,s2))\n",
    "        return 2\n",
    "    else:\n",
    "        print(\"\\nFor the cointegration problem, the independent variable in regression between the asset classes is {} and the dependent variable is {}\".format(s2,s1))\n",
    "        \n",
    "        return 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Robustnes of Cointegration Weights\n",
    "\n",
    "The robustness of the parameters are tested over time. The cointegration weights over 2 different time scales and using a t-statistic test, an analysis has been made whether the weightts are identical.\n",
    "\n",
    "The R^2 value of the Error Correction Model is analysed to check whether the lagged residual and delta of the independent asset are good estimator of the change in price of the dependent asset. If a high R^2 score is observed, a higher proporrtion of the variance is explained using the lagged residual and the cointegration is more robust. \n",
    "\n",
    "随时间测试参数的稳健性。使用t统计量测试2个不同时间尺度下的协整权重，并进行分析，判断这些权重是否相同。\n",
    "\n",
    "分析误差修正模型的R^2值，以检查滞后残差和独立资产的变化是否是依赖资产价格变化的良好估计量。如果观察到较高的R^2分数，则使用滞后残差解释了更高比例的方差，协整更为稳健。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def robustness(xdata,ydata,long_xdata,long_ydata,ci):\n",
    "    \n",
    "    # Finding Cointegration Weights of Short Period\n",
    "    coef,intercept,resid=regression(xdata,ydata)\n",
    "    # Finding Cointegration Weights of Long Period \n",
    "    long_coef,long_intercept,long_resid=regression(long_xdata,long_ydata)\n",
    "    \n",
    "    # Testing the R-squared of the cointegration weight\n",
    "    ecm_object=test_significance(xdata,ydata,resid)\n",
    "    print(\"\\nThe R2 score of the error correction model is {}. This means the lagged spread explains {}% of the total variance. \".format(ecm_object.rsquared,ecm_object.rsquared*100))\n",
    "\n",
    "    t_statistic,p_value=ttest_ind(resid,long_resid)\n",
    "    \n",
    "    if abs(t_statistic) < t.ppf(0.95,len(xdata)):\n",
    "        print (\"\\nThe t-statistic is {} and the spread over 2 periods are similar according to t-statistic test\".format(t_statistic))\n",
    "    else:\n",
    "        print (\"\\nThe t-statistic is {} and the spread over 2 periods are not similar according to t-statistic test\".format(t_statistic))\n",
    "        print (\"As co-integration is not significant, consider the use of Kalman Filters\")\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting the Spread to Ornstein Uhlenbeck Process\n",
    "\n",
    "Using the analytical autoregressive solution of the Ornstein Uhlenbach process, the mean, half life and the equivalent diffusion of the mean reverting spread. The parameters are calculated using the coefficients of the autoregression equation as given in the report. \n",
    "\n",
    "If the analytical solution is fit to a static regression, only a single set of parameters for the process is produced. \n",
    "\n",
    "If Kalman Filters are used to fit to the analytical solution to the spread, a smooth set of variable parameters is produced which are time varying. The delta parameter can be used to determine the degree and frequency of rebalancing\n",
    "\n",
    "使用Ornstein Uhlenbach过程的解析自回归解，计算均值、半衰期和均值回归差异的等效扩散。使用报告中给出的自回归方程的系数计算参数。\n",
    "\n",
    "如果将解析解拟合为静态回归，将仅产生一个过程的一组参数。\n",
    "\n",
    "如果使用卡尔曼滤波器将解析解拟合到差异中，将产生一组平滑的可变参数，这些参数随时间变化。可以使用delta参数来确定再平衡的程度和频率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_strategy(residuals,kalman=False,delta=1e-4,display=True):\n",
    "    \n",
    "    # Defining the dataset to be fit to the analytical OU process equation\n",
    "    tau=float(1)/252\n",
    "    spread=pd.DataFrame(residuals)\n",
    "    spread.columns=['Spread']\n",
    "    spread['Spreadt-1']=spread['Spread'].shift(1)\n",
    "    spread.dropna(inplace=True)\n",
    "    target_y=pd.DataFrame(spread['Spread'])\n",
    "    target_y.columns=['y']\n",
    "    spread.drop(['Spread'],axis=1,inplace=True)\n",
    "\n",
    "    if kalman == False:\n",
    "        # Calculating OU parameters from linear regression \n",
    "        autoregression_coefficient,mean_reverting_term,resids=regression(spread['Spreadt-1'],target_y['y'])\n",
    "        # Creating an array of OU parameters for each trading session. The parameters in this case are constant for each time session\n",
    "        mean_reverting_term=np.repeat(mean_reverting_term,len(resids))\n",
    "        autoregression_coefficient=np.repeat(autoregression_coefficient,len(resids))\n",
    "    \n",
    "    else:\n",
    "        # Calculating the OU parameters using Kalman Filters\n",
    "        autoregression_coefficient,mean_reverting_term,resids=dynamic_regression(spread['Spreadt-1'],target_y['y'],delta)\n",
    "               \n",
    "    # Computing Half life of the process\n",
    "    speed_of_reversion=-1*np.log(np.absolute(autoregression_coefficient))/tau\n",
    "\n",
    "    # Computing the mean about which the OU process reverts\n",
    "    mean=mean_reverting_term/(1-autoregression_coefficient)\n",
    "    if np.isnan(mean).any():\n",
    "        mean=np.nan_to_num(mean)\n",
    "        \n",
    "    # Computing the instantaneous and the equivalent diffusion for the spread\n",
    "    diffusion_ou=((2*speed_of_reversion*np.var(residuals))/(1-np.exp(-2*speed_of_reversion*tau)))**0.5\n",
    "    speed_of_reversion[speed_of_reversion<=0]=1e-15\n",
    "    diffusion_eq=diffusion_ou/((2*speed_of_reversion)**0.5)\n",
    "    half_life=np.log(2)/speed_of_reversion\n",
    "    \n",
    "    \n",
    "    \n",
    "    if display == True:\n",
    "        print (\"\\nThe spread fitted to the Ornstein Uhlenbeck Process has the following parameters: \")        \n",
    "        if kalman == False:\n",
    "            print (\"The mean of reversion for this spread is {} \\nSigma of reversion for this spread is {} \\nThe speed of reversion, short term diffusion and half life of the OU process is {}, {} and {}\".format(mean[0],diffusion_eq[0],speed_of_reversion[0],diffusion_ou[0],half_life[0]))\n",
    "        else:\n",
    "            \n",
    "            plt.figure(figsize=(24, 24))\n",
    "            iqr_mr=iqr(mean)*4\n",
    "            iqr_sr=iqr(diffusion_eq)*4\n",
    "            iqr_spr=iqr(speed_of_reversion)*4\n",
    "            iqr_ds=iqr(diffusion_ou)*4\n",
    "            lim=[iqr_mr,iqr_sr,iqr_spr,iqr_ds]\n",
    "            xlabel='Trading Sessions'\n",
    "            ylabel=['OU Mean','OU Diffusion','Rate of Revesion','Diffusion over short time']\n",
    "            title=['Mean of Reversion','Sigma of Revesion','Speed of Revesion','Diffusion over short timescale']\n",
    "            subplots=[411,412,413,414]\n",
    "            labels=['Mean of Reversion','Sigma of Revesion','Speed of Reversion','Diffusion over short timescale']\n",
    "            plots=[mean,diffusion_eq,speed_of_reversion,diffusion_ou]\n",
    "            \n",
    "            \n",
    "            for i in range(0,4):\n",
    "                plt.subplot(subplots[i])\n",
    "                plt.title(title[i])\n",
    "                plt.xlabel(xlabel)\n",
    "                plt.ylabel(ylabel[i])\n",
    "                plt.ylim(np.percentile(plots[i],25)-lim[i],np.percentile(plots[i],75)+lim[i])\n",
    "                plt.plot(plots[i],label=labels[i])\n",
    "                plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "    return mean,diffusion_eq "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trade design \n",
    "\n",
    "Trade design implements the trade simulation, signal generation and optimization of trading parameters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of the trade signal generation and the simulation of trades\n",
    "\n",
    "Initially, for each trading session it is checked whether a trade is executing or not. If a trade is executing, the selling price for the current session is calculated and the current portfolio value is updated based on the current price. Then the current price is checked against the selling price and the allowable slippage and the trade is closed and a sell signal is generated. If the trade is not closed, the price is checked for the stoploss estabilished during the purchase and if it is breached the trade is closed and a sell signal is generated. The duration of the trade is then checked against the maximum trade duration limit and the trade is closed if it is breached and a sell signal is generated. \n",
    "\n",
    "If the trade is not executing, the buying price and allowable slippage for each trading session is calculated and it is checked whether the current price is within the allowable buying range. If yes, a trade is initiated and a buy signal is generated. The stoploss for that trade is then calculated and the portfolio value is updated. \n",
    "\n",
    "If Kalman Filters have been used for fitting to the mean reversion process, the equivalent diffusion and the mean is variable for each trading session is variable. Hence, the entry and exit price range for each session is re-calculated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trade(data,spread,mean,diffusion_eq,weight,entry_point,slippage=0.05,rfr=0.02,max_trade_exit=np.float('Inf'),stoploss=0.5,plot=True):\n",
    "    #,diff_spread\n",
    "    # Initialising trading Flags \n",
    "    ydata=data['ydata'].values\n",
    "    xdata=data['xdata'].values\n",
    "    diff_spread=data['ydata']-weight*data['xdata']\n",
    "    diff_spreadd=diff_spread.values\n",
    "    \n",
    "    top_trade_executing=0 #Corresponds to a trade entering from above the mean\n",
    "    bottom_trade_executing=0 #Corresponds to a trad entering from below the mean\n",
    "    entry_price=0\n",
    "    trade_executing=0\n",
    "    \n",
    "    buy=[]\n",
    "    sell=[]\n",
    "    status=[]\n",
    "    pl=np.zeros(len(spread),dtype=np.float)\n",
    "    returns=np.zeros(len(spread),dtype=np.float)\n",
    "    portfolio_value=np.zeros(len(spread),dtype=np.float)\n",
    "    flag1=0\n",
    "    flag2=0\n",
    "    \n",
    "    if slippage == -999:\n",
    "        flag1=1\n",
    "    \n",
    "    if flag1 != 1:\n",
    "\n",
    "        slipped_entry_top = np.zeros(len(spread), dtype=float)\n",
    "        slipped_entry_bottom = np.zeros(len(spread), dtype=float)\n",
    "           \n",
    "    # Trying to plot stoploss\n",
    "    stop = np.zeros(len(spread), dtype=float)\n",
    "    if stoploss == -999:\n",
    "        flag2=1\n",
    "        stoploss=np.float('Inf')\n",
    "        stop.fill(np.nan)\n",
    "    \n",
    "    if max_trade_exit == -999:\n",
    "        max_trade_exit=np.float('Inf')\n",
    "    k=0\n",
    "\n",
    "    for i in range(0,len(spread)):\n",
    "                \n",
    "            # Mean is the exit point for an executing trade \n",
    "            exit=mean[i]\n",
    "            top_entry= mean[i] + diffusion_eq[i]*entry_point\n",
    "            bottom_entry= mean[i] - diffusion_eq[i]*entry_point\n",
    "            \n",
    "            if flag1 != 1:\n",
    "                    \n",
    "                if top_entry > 0:\n",
    "                    slipped_entry_top[i]=float(1-slippage)*top_entry\n",
    "\n",
    "                else:\n",
    "                    slipped_entry_top[i]=float(1+slippage)*(top_entry)\n",
    "                \n",
    "                if bottom_entry < 0:\n",
    "                    slipped_entry_bottom[i]=float(1-slippage)*bottom_entry\n",
    "\n",
    "                else:\n",
    "                    slipped_entry_bottom[i]=float(1+slippage)*bottom_entry\n",
    "                \n",
    "            \n",
    "            # If no trade in current execution\n",
    "            if trade_executing == 0:\n",
    "\n",
    "                ''' Dependent on whether the current price is above or below mean, we calculate the \n",
    "                    price at which we can enter a trade and the associated slippage based on the mean and \n",
    "                    equivalent diffusion for the given trading session'''\n",
    "                \n",
    "                if spread[i] > mean[i]:\n",
    "                    entry=top_entry\n",
    "                    if flag1 != 1:\n",
    "                        slipped_entry=slipped_entry_top[i]\n",
    "                else:\n",
    "                    entry=bottom_entry\n",
    "                    if flag1 != 1:\n",
    "                        slipped_entry=slipped_entry_bottom[i]\n",
    "                \n",
    "                \n",
    "                ''' We check the session price against the computer range of entry and update \n",
    "                    the required flags. The stoploss price for that trade is calculated and the\n",
    "                    portfolio value is updated'''\n",
    "                \n",
    "                if spread[i] > mean[i]:\n",
    "                    if flag1 == 1:\n",
    "                        if spread[i]==entry or (i!=0 and spread[i-1]>entry and spread[i]<entry):\n",
    "                             trade_executing=1   \n",
    "                    \n",
    "                    else:\n",
    "                        if spread[i] <= entry and  spread[i] >= slipped_entry:\n",
    "                            trade_executing=1\n",
    "                            \n",
    "                    if trade_executing ==1:\n",
    "                        buy.append(i)\n",
    "                        top_trade_executing=1\n",
    "                        status.append(1) \n",
    "                        portfolio_value[i]=ydata[i]+weight[i]*xdata[i]\n",
    "                        entry_price=spread[i]\n",
    "                                                \n",
    "                        if entry < 0:\n",
    "                            stoploss_exit=(1-stoploss)*(entry)\n",
    "                        else:\n",
    "                            stoploss_exit=(1+stoploss)*entry\n",
    "                        \n",
    "                        stop[i]=stoploss_exit\n",
    "                            \n",
    "            \n",
    "                if spread[i] < mean[i]:\n",
    "                    if flag1 == 1:\n",
    "                        if spread[i] == entry or (i!=0 and spread[i-1]<entry and spread[i]>entry):\n",
    "                             trade_executing=1\n",
    "                    else:\n",
    "                        if spread[i] >= entry and spread[i] <= slipped_entry:\n",
    "                            trade_executing=1\n",
    "                            \n",
    "                    if trade_executing ==1:    \n",
    "                        buy.append(i)\n",
    "                        bottom_trade_executing=1\n",
    "                        status.append(-1)\n",
    "                        portfolio_value[i]=ydata[i]+weight[i]*xdata[i]\n",
    "                        entry_price=spread[i]\n",
    "                        \n",
    "                        if entry > 0:\n",
    "                            stoploss_exit=(1-stoploss)*(entry)\n",
    "                        else:\n",
    "                            stoploss_exit=(1+stoploss)*entry\n",
    "                        stop[i]=stoploss_exit\n",
    "            else:\n",
    "                ''' If no trade is being executed, the portfolio value is first updated, and then the current \n",
    "                    price of asset is checked against the previously computed exit range. If the price is within the \n",
    "                    exit range, the position is liquidated. If not it is then checked whether the current price\n",
    "                    breaches the defined stoploss or the trade duration execeeds the maximum allowable time in a trade.\n",
    "                    In case of a breach the position is again closed'''\n",
    "                \n",
    "                stop[i]=stoploss_exit\n",
    "                \n",
    "                if top_trade_executing == 1:\n",
    "                    \n",
    "                    pl[i]=weight[i]*(xdata[i]-xdata[i-1])+(ydata[i-1]-ydata[i])\n",
    "                    portfolio_value[i]=portfolio_value[i-1]+pl[i]\n",
    "                    \n",
    "                    \n",
    "                    if spread[i-1]>=exit and spread[i]<=exit:\n",
    "                        top_trade_executing=0\n",
    "                                        \n",
    "                    if top_trade_executing == 0:\n",
    "                        trade_executing=0\n",
    "                        sell.append(i)\n",
    "                        k=k+1\n",
    "                \n",
    "                    elif spread[i] > stoploss_exit:\n",
    "                        trade_executing=0\n",
    "                        top_trade_executing=0\n",
    "                        sell.append(i)\n",
    "                        status[k]=status[k]*3\n",
    "                        k=k+1\n",
    "                \n",
    "                \n",
    "                if bottom_trade_executing==1:\n",
    "                    pl[i]=weight[i]*(xdata[i-1]-xdata[i])+(ydata[i]-ydata[i-1])\n",
    "                    portfolio_value[i]=portfolio_value[i-1]+pl[i]\n",
    "                    if spread[i-1]<=exit and spread[i]>=exit:\n",
    "                        bottom_trade_executing=0\n",
    "                    \n",
    "                            \n",
    "                    if bottom_trade_executing == 0:\n",
    "                        trade_executing=0\n",
    "                        sell.append(i)\n",
    "                        k=k+1   \n",
    "                \n",
    "                    elif spread[i] < stoploss_exit:\n",
    "                        trade_executing=0\n",
    "                        bottom_trade_executing=0\n",
    "                        sell.append(i)\n",
    "                        status[k]=status[k]*3\n",
    "                        k=k+1\n",
    "                \n",
    "                \n",
    "                if trade_executing ==1 and i-buy[k] == max_trade_exit:\n",
    "                    trade_executing=0\n",
    "                    bottom_trade_executing=0\n",
    "                    top_trade_executing=0\n",
    "                    sell.append(i)\n",
    "                    status[k]=status[k]*2\n",
    "                    k=k+1\n",
    "        \n",
    "            ''' Based on the trading activity in the current and previous sesison the portfolio \n",
    "            value is computed and the returns are calculated'''\n",
    "            \n",
    "            if i!=0 and portfolio_value[i-1] != 0 and i-1 not in sell:\n",
    "                returns[i]=(portfolio_value[i]-portfolio_value[i-1])/(portfolio_value[i-1])\n",
    "            \n",
    "            \n",
    "            ''' If no trading activity takes place, it is assumed that the return is the risk free \n",
    "            rate i.e. if capital is not invested in the trade it is kept in a bank account'''\n",
    "            \n",
    "            if returns[i] == 0:\n",
    "                returns[i]+=(rfr+1)**(float(1)/252)-1       \n",
    "            \n",
    "    if plot == True:\n",
    "        plt.figure(1, figsize=(24, 24))\n",
    "\n",
    "        s_iqr=0.75*iqr(spread)\n",
    "        plt.ylim(min(spread)-s_iqr,max(spread)+s_iqr)\n",
    "        plt.plot(mean,label=\"Mean of Reversion\",linestyle='--',linewidth=3)\n",
    "        plt.plot(mean + diffusion_eq*entry_point,label=\"Entry Bounds\",linestyle='--',linewidth=3)\n",
    "        plt.plot(mean - diffusion_eq*entry_point,label=\"Entry Bounds\",linestyle='--',linewidth=3)\n",
    "        plt.plot(spread,label=\"Reverting Spread\",linewidth=5)\n",
    "        if flag1 != 1:\n",
    "            plt.plot(slipped_entry_bottom,label='Slippage Range for Trade from below the mean',linestyle='--',linewidth=3)\n",
    "            plt.plot(slipped_entry_top,label='Slippage Range for Trade from above the mean',linestyle='--',linewidth=3)\n",
    "        if flag2 != 1:\n",
    "            plt.plot(stop,label=\"Stoploss\",linestyle=':',linewidth=3)\n",
    "    \n",
    "        b_array=np.zeros(len(spread), dtype=float)\n",
    "        b_array.fill(np.nan)\n",
    "        b_array[buy]=spread[buy]\n",
    "    \n",
    "        s_array=np.zeros(len(spread), dtype=float)\n",
    "        s_array.fill(np.nan)\n",
    "        s_array[sell]=spread[sell]\n",
    "\n",
    "        plt.plot(b_array,marker='o',label=\"Buy Signals\",markersize=15)\n",
    "        plt.plot(s_array,marker='o',label=\"Sell Signals\",markersize=15)\n",
    "        \n",
    "        plt.xlabel('Trading Sessions')\n",
    "        plt.ylabel('Spread (Rupees)')\n",
    "        plt.title(\"Simulation of trades on the spread\")\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.show()\n",
    "\n",
    "    return buy,sell,status,portfolio_value,returns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing trading parameters\n",
    "\n",
    "Trading Parameters decide the success of the strategy. In the current implementation, the entry and exit bounds, slippage in spread, stoploss in spread can alter the trading strategy. To find optimal parameters, an input range for the acceptable values are taken as input. 100 values are interpolated within a range and a strategy is simulated for each of these value. An optimization criteria like profit or duration can then be maximised. A report is generated and the optimal value of parameter is outlined\n",
    "\n",
    "If we use Kalman Filters, the delta parameter will determine the the degree of rebalancing of the generated coefficients and intercept. We can alter this parameter to find the optimal spread. We can either alter delta while computing residuals or alter delta while fitting spread to the OU process. Optimisation for both parameters is done using the above specified methodology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def optimization_plot(cum_rets,es,sharpe,risk,avg_duration,avg_profit,xdata,xlabel,opt_ind,opt_crit,opt_data):\n",
    "    plot_data=[avg_profit,cum_rets,sharpe,risk,es,avg_duration]\n",
    "    plot_labels=['Avg. Profit','Cumulative Return','Sharpe Ratio','Risk','Expected Shortfall','Average Duration']\n",
    "    if opt_crit not in plot_labels:\n",
    "        plot_labels.append(opt_crit)\n",
    "        plot_data.append(opt_data)\n",
    "    \n",
    "    plots=len(plot_data)\n",
    "    plt.figure(figsize=(42, 24))\n",
    "    for lab,i in zip(plot_labels,range(1,len(plot_labels)+1)):\n",
    "        plt.subplot(int('{}{}{}'.format(plots,1,i)))\n",
    "        plt.plot(xdata,plot_data[i-1])\n",
    "        plt.plot(xdata[opt_ind:opt_ind+1],plot_data[i-1][opt_ind:opt_ind+1],marker='o',label='Optimal Parameter')\n",
    "        #plt.xlabel(xlabel)\n",
    "        plt.ylabel(plot_labels[i-1])\n",
    "        plt.title('{} v/s {}'.format(plot_labels[i-1],xlabel))\n",
    "        plt.legend()\n",
    "    \n",
    "    plt.xlabel(xlabel)\n",
    "    plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def optimization_results(report,lower_bound, upper_bound,optimization_label,optimization_criteria,flag,display=False):\n",
    "    form=''\n",
    "    valid_trades=report[report['Total Trades'] > 0]\n",
    "    # Only optimising where valid trades are made\n",
    "    if valid_trades.shape[0] > 0:\n",
    "        if flag==0:\n",
    "            opt_ind=valid_trades[optimization_criteria].idxmin()\n",
    "            if opt_ind == len(report)-1:\n",
    "                if optimization_label == 'Residual Delta/Mean Reversion Delta':\n",
    "                    optimal_resid_delta=valid_trades[-1:]['Residual Delta'].values\n",
    "                    optimal_mr_delta=valid_trades[-1:]['Mean Reversion Delta'].values\n",
    "                else:\n",
    "                    optimal_parameter=valid_trades[-1:][optimization_label].values\n",
    "            else:\n",
    "                if optimization_label == 'Residual Delta/Mean Reversion Delta':\n",
    "                    optimal_resid_delta=valid_trades[opt_ind:opt_ind+1]['Residual Delta'].values\n",
    "                    optimal_mr_delta=valid_trades[opt_ind:opt_ind+1]['Mean Reversion Delta'].values\n",
    "                else:\n",
    "                    optimal_parameter=valid_trades[opt_ind:opt_ind+1][optimization_label].value\n",
    "            form='minimisation'\n",
    "        \n",
    "        else:\n",
    "            opt_ind=valid_trades[optimization_criteria].idxmax()\n",
    "            if opt_ind == len(report)-1:\n",
    "                if optimization_label == 'Residual Delta/Mean Reversion Delta':\n",
    "                    optimal_resid_delta=valid_trades[-1:]['Residual Delta'].values\n",
    "                    optimal_mr_delta=valid_trades[-1:]['Mean Reversion Delta'].values\n",
    "                else:\n",
    "                    optimal_parameter=valid_trades[-1:][optimization_label].values\n",
    "            else:\n",
    "                if optimization_label == 'Residual Delta/Mean Reversion Delta':\n",
    "                    optimal_resid_delta=valid_trades[opt_ind:opt_ind+1]['Residual Delta'].values\n",
    "                    optimal_mr_delta=valid_trades[opt_ind:opt_ind+1]['Mean Reversion Delta'].values\n",
    "                else:\n",
    "                    optimal_parameter=valid_trades[opt_ind:opt_ind+1][optimization_label].values\n",
    "            form='maximisation'\n",
    "                    \n",
    "        if display == True:\n",
    "            print (\"The optimization report for {} is :\".format(optimization_label))\n",
    "            print (report)\n",
    "            \n",
    "        if optimization_label == 'Residual Delta/Mean Reversion Delta':\n",
    "            print (\"Optimal Residual Delta and Mean Reversion Delta of a trade for this pair with {} of {} is {} and {}\".format(form,optimization_criteria,optimal_resid_delta,optimal_mr_delta))\n",
    "            df_rec=report['Residual Delta'].astype(str)+'/'+report['Mean Reversion Delta'].astype(str)\n",
    "            print (\"\\n The optimization plot for {} is: \".format(optimization_label))\n",
    "            df_rec=report['Residual Delta'].astype(str)+'/'+report['Mean Reversion Delta'].astype(str)\n",
    "            optimization_plot(report['Cumulative Return'],report['Expected Shortfall'],report['Sharpe Ratio'],report['Standard Deviation of Returns'],report['Average Trade Duration'],report['Average Profit'],df_rec,'Residual Delta/Mean Reversion Delta',opt_ind,optimization_criteria,report[optimization_criteria])\n",
    "            return optimal_resid_delta[0],optimal_mr_delta[0]\n",
    "    \n",
    "        else:\n",
    "            print (\"Optimal {} for this spread with {} of {} is {}\".format(optimization_label,form,optimization_criteria,optimal_parameter))\n",
    "            print (\"\\n The optimization plot for {} is: \".format(optimization_label))\n",
    "            optimization_plot(report['Cumulative Return'],report['Expected Shortfall'],report['Sharpe Ratio'],report['Standard Deviation of Returns'],report['Average Trade Duration'],report['Average Profit'],report[optimization_label],optimization_label,opt_ind,optimization_criteria,report[optimization_criteria])\n",
    "            return optimal_parameter[0]\n",
    "            \n",
    "    else:\n",
    "        print(\"No trades were made for any specifed value of {}. The return parameters are average of the minimal and maximal bounds\".format(optimization_label))\n",
    "        if optimization_label == 'Residual Delta/Mean Reversion Delta':\n",
    "            optimal_resid_delta=[(upper_bound+lower_bound)*0.5]\n",
    "            optimal_mr_delta=[(upper_bound+lower_bound)*0.5]\n",
    "            return optimal_resid_delta[0],optimal_mr_delta[0]\n",
    "\n",
    "        else:       \n",
    "            optimal_parameter=[(upper_bound+lower_bound)*0.5]\n",
    "            return optimal_parameter[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def optimize_parameter(lower_bound, upper_bound,optimization_label,optimization_criteria,flag,val,display=False,*trade_parameters):\n",
    "    data,spread,mean,entry_point,diffusion_eq,coint,slippage,rfr,max_trade_exit,stoploss,comm_short,comm_long,dates=trade_parameters\n",
    "    \n",
    "    # Generating set of probable parameter values\n",
    "    if optimization_label == 'Maximum Trade Duration':\n",
    "        probables=np.unique(np.linspace(lower_bound,upper_bound,val,dtype=int))\n",
    "\n",
    "    else:\n",
    "        probables=np.linspace(lower_bound,upper_bound,val)\n",
    "    \n",
    "    # Generating set of probable parameter values\n",
    "    form=''\n",
    "    report=pd.DataFrame()\n",
    "    weight=np.repeat(coint[0][1],len(mean))\n",
    "    data=data[-len(mean):]\n",
    "    for i in probables:\n",
    "            if optimization_label == 'Entry Bound':\n",
    "                buy,sell,status,portfolio_value,returns=trade(data,spread,mean,diffusion_eq,weight,i,slippage,rfr,max_trade_exit,stoploss,plot=False)\n",
    "            if optimization_label == 'Slippage':\n",
    "                buy,sell,status,portfolio_value,returns=trade(data,spread,mean,diffusion_eq,weight,entry_point,i,rfr,max_trade_exit,stoploss,plot=False)\n",
    "            if optimization_label == 'Maximum Trade Duration':\n",
    "                buy,sell,status,portfolio_value,returns=trade(data,spread,mean,diffusion_eq,weight,entry_point,slippage,rfr,i,stoploss,plot=False)\n",
    "            if optimization_label == 'Stoploss':\n",
    "                buy,sell,status,portfolio_value,returns=trade(data,spread,mean,diffusion_eq,weight,entry_point,slippage,rfr,max_trade_exit,i,plot=False)\n",
    "            \n",
    "            df_temp=trade_sheet(buy,sell,status,data,coint,comm_short,comm_long)\n",
    "            df,temp,tempu=backtest(df_temp,returns,dates,rfr,display=False)\n",
    "            df[optimization_label]=i\n",
    "            report=report.append(df,ignore_index=True)\n",
    "            \n",
    "    optimal_parameter=optimization_results(report,lower_bound, upper_bound,optimization_label,optimization_criteria,flag)\n",
    "    return optimal_parameter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def optimize_residual_delta(lower_bound, upper_bound,optimization_criteria,flag,val,ou_flag,display=False,*trade_parameters):\n",
    "\n",
    "    ou_delta,data,entry_point,slippage,rfr,max_trade_exit,stoploss,commission_short,commission_long,dates=trade_parameters\n",
    "    # Generating set of probable parameter values\n",
    "    probables=np.geomspace(lower_bound,upper_bound,val)\n",
    "    report=pd.DataFrame()\n",
    "    \n",
    "    for i in probables:\n",
    "        #Simulate trading for the given parameter\n",
    "        a,b,spread=dynamic_regression(data['xdata'],data['ydata'],i)\n",
    "        if ou_flag == 1:\n",
    "            mean,diffeq=build_strategy(spread,True,ou_delta,display=False)\n",
    "        else:\n",
    "            mean,diffeq=build_strategy(spread,display=False)\n",
    "            \n",
    "        spread=spread[-len(mean):]\n",
    "        data=data[-len(mean):]\n",
    "        a=a[-len(mean):]\n",
    "        buy,sell,status,portfolio_value,returns=trade(data,spread,mean,diffeq,a,entry_point,slippage,rfr,max_trade_exit,stoploss,plot=False)\n",
    "        coint=np.vstack([np.ones(len(a)),a]).T\n",
    "        df_temp=trade_sheet(buy,sell,status,data,coint,commission_short,commission_long)\n",
    "        df,temp,tempu=backtest(df_temp,returns,dates,rfr,False)\n",
    "        df['Residual Delta']=i\n",
    "        report=report.append(df,ignore_index=True)\n",
    "    \n",
    "    # Finding the optimal parameter based on the given criteria\n",
    "    optimal_parameter=optimization_results(report,lower_bound, upper_bound,'Residual Delta',optimization_criteria,flag,display)\n",
    "    return optimal_parameter\n",
    "\n",
    "\n",
    "\n",
    "def optimize_mean_reversion_delta(lower_bound,upper_bound,optimization_criteria,flag,val,display=False,*trade_parameters):\n",
    "    weight,data,spread,entry_point,slippage,rfr,max_trade_exit,stoploss,commission_short,commission_long,dates=trade_parameters\n",
    "    \n",
    "    # Generating set of probable parameter values\n",
    "    probables=np.geomspace(lower_bound,upper_bound,val)\n",
    "    report=pd.DataFrame()\n",
    "\n",
    "    for i in probables:\n",
    "        \n",
    "        #Simulate trading for the given parameter\n",
    "        mean,diffeq=build_strategy(spread,True,i,display=False)\n",
    "        spread=spread[-len(mean):]\n",
    "        data=data[-len(mean):]\n",
    "        weight=weight[-len(mean):]\n",
    "        buy,sell,status,portfolio_value,returns=trade(data,spread,mean,diffeq,weight,0.4,slippage,rfr,max_trade_exit,stoploss,plot=False)\n",
    "        coint=np.vstack([np.ones(len(weight)),weight]).T\n",
    "        df_temp=trade_sheet(buy,sell,status,data,coint,commission_short,commission_long)\n",
    "        df,temp,tempu=backtest(df_temp,returns,dates,rfr,False)\n",
    "        df['Mean Reversion Delta']=i\n",
    "        report=report.append(df,ignore_index=True)\n",
    "    \n",
    "    optimal_parameter=optimization_results(report,lower_bound, upper_bound,'Mean Reversion Delta',optimization_criteria,flag,display)\n",
    "    return optimal_parameter\n",
    "\n",
    "def optimize_both_delta(lower_bound, upper_bound,optimization_criteria,flag,val,display=False,*trade_parameters):\n",
    "\n",
    "    data,entry_point,slippage,rfr,max_trade_exit,stoploss,commission_short,commission_long,dates=trade_parameters\n",
    "    # Generating set of probable parameter values\n",
    "    probables_resid=np.geomspace(lower_bound,upper_bound,val)\n",
    "    probables_ou=np.geomspace(lower_bound,upper_bound,val)\n",
    "    report=pd.DataFrame()\n",
    "    \n",
    "    for i in probables_resid:\n",
    "        for j in probables_ou:\n",
    "        #Simulate trading for the given parameter\n",
    "            a,b,spread=dynamic_regression(data['xdata'],data['ydata'],i)\n",
    "            mean,diffeq=build_strategy(spread,True,j,display=False)\n",
    "                    \n",
    "            spread=spread[-len(mean):]\n",
    "            data=data[-len(mean):]\n",
    "            a=a[-len(mean):]\n",
    "            buy,sell,status,portfolio_value,returns=trade(data,spread,mean,diffeq,a,entry_point,slippage,rfr,max_trade_exit,stoploss,plot=False)\n",
    "            coint=np.vstack([np.ones(len(a)),a]).T\n",
    "            df_temp=trade_sheet(buy,sell,status,data,coint,commission_short,commission_long)\n",
    "            df,temp,tempu=backtest(df_temp,returns,dates,rfr,False)\n",
    "            df['Residual Delta']=i\n",
    "            df['Mean Reversion Delta']=j\n",
    "            report=report.append(df,ignore_index=True)\n",
    "    \n",
    "        \n",
    "    optimal_resid_delta,optimal_mr_delta=optimization_results(report,lower_bound, upper_bound,'Residual Delta/Mean Reversion Delta',optimization_criteria,flag,display)\n",
    "    return optimal_resid_delta,optimal_mr_delta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def optimize(data,spread,mean,diffusion_eq,entry_point,dates,coint,slippage,rfr,max_trade_exit,stoploss,commission_short=0,commission_long=0):\n",
    "    \n",
    "    params=(data,spread,mean,entry_point,diffusion_eq,coint,slippage,rfr,max_trade_exit,stoploss,commission_short,commission_long,dates)\n",
    "    for i in range(0,4):\n",
    "        inp=int(raw_input(\"Enter optimisation parameter: Entry Point - 1, Slippage - 2, Max Duration - 3, Stoploss - 4, Exit - 5: \"))\n",
    "        #inp=inp+1\n",
    "        if inp == 5:\n",
    "            break\n",
    "        \n",
    "        lower_bound=float(raw_input(\"Lower Bound of the optimization criteria: \"))\n",
    "        upper_bound=float(raw_input(\"Upper Bound of the optimization criteria: \"))\n",
    "        val=int(raw_input(\"Number of interpolations for each parameter: \"))\n",
    "        optimization_criteria=raw_input(\"Optimization attribute: Total Trades, Complete Trades, Incomplete Trades, Profit Trades, Loss Trades, Total Profit, Average Trade Duration, Average Profit, Win Ratio, Average Profit on Profitable Trades, Standard Deviation of Returns, Value at Risk, Expected Shortfall, Sharpe Ratio, Sortino Ratio, Cumulative Return, Market Alpha, Market Beta, HML Beta, SMB Beta, WML Beta, Momentum Beta,Fama French Four Factor Alpha: \")\n",
    "        flag=int(raw_input(\"Minimise-0, Maximise-1: \"))\n",
    "        if inp == 1:\n",
    "            entry_point=optimize_parameter(lower_bound,upper_bound,'Entry Bound',optimization_criteria,flag,val,False,*params)\n",
    "\n",
    "        elif inp == 2:\n",
    "            slippage=optimize_parameter(lower_bound,upper_bound,'Slippage',optimization_criteria,flag,val,False,*params)\n",
    "            \n",
    "        elif inp == 3:\n",
    "            \n",
    "            max_trade_exit=optimize_parameter(lower_bound,upper_bound,'Maximum Trade Duration',optimization_criteria,flag,val,False,*params)\n",
    "        \n",
    "        elif inp == 4:\n",
    "            \n",
    "            stoploss=optimize_parameter(lower_bound,upper_bound,'Stoploss',optimization_criteria,flag,val,False,*params)\n",
    "\n",
    "\n",
    "    return entry_point,slippage,max_trade_exit,stoploss\n",
    "\n",
    "\n",
    "def optimize_delta(data,spread,entry_point,dates,weight,slippage,rfr,max_trade_exit,stoploss,commission_short,commission_long,flag1,ou_delta=0):\n",
    "    lower_bound=float(raw_input(\"Lower Bound of the optimization criteria: \"))\n",
    "    upper_bound=float(raw_input(\"Upper Bound of the optimization criteria: \"))\n",
    "    val=int(raw_input(\"Number of interpolations for each parameter: \"))\n",
    "    optimization_criteria=raw_input(\"Optimization attribute: Total Trades, Complete Trades, Incomplete Trades, Profit Trades, Loss Trades, Total Profit, Average Trade Duration, Average Profit, Win Ratio, Average Profit on Profitable Trades, Standard Deviation of Returns, Value at Risk, Expected Shortfall, Sharpe Ratio, Sortino Ratio, Cumulative Return, Market Alpha, Market Beta, HML Beta, SMB Beta, WML Beta, Momentum Beta,Fama French Four Factor Alpha: \")\n",
    "    flag2=int(raw_input(\"Minimise-0, Maximise-1: \"))\n",
    "\n",
    "\n",
    "    if flag1 == 2 or flag1 == 4:\n",
    "        trade_parameters=(ou_delta,data,entry_point,slippage,rfr,max_trade_exit,stoploss,commission_short,commission_long,dates)\n",
    "        if flag1 == 4:\n",
    "            resid_delta=optimize_residual_delta(lower_bound,upper_bound,optimization_criteria,flag2,val,1,False,*trade_parameters)\n",
    "        else:\n",
    "            resid_delta=optimize_residual_delta(lower_bound,upper_bound,optimization_criteria,flag2,val,0,False,*trade_parameters)\n",
    "        return resid_delta\n",
    "        \n",
    "    if flag1 == 3:\n",
    "        trade_parameters=(weight,data,spread,entry_point,slippage,rfr,max_trade_exit,stoploss,commission_short,commission_long,dates)\n",
    "        return optimize_mean_reversion_delta(lower_bound,upper_bound,optimization_criteria,flag2,val,False,*trade_parameters)\n",
    "        \n",
    "    if flag1 == 5:\n",
    "        trade_parameters=(data,entry_point,slippage,rfr,max_trade_exit,stoploss,commission_short,commission_long,dates)\n",
    "        return optimize_both_delta(lower_bound,upper_bound,optimization_criteria,flag2,val,False,*trade_parameters)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Producing a trade details of the strategy\n",
    "\n",
    "Generating the date and price of entering and closing the trade, the profit and the duration of each trade is calculated from the buy and sell signals generated from each strategy  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def commission(price_s1,price_s2,commission_short,commission_long):\n",
    "    comm_s1=abs(price_s1*commission_long if price_s1 > 0 else price_s1*commission_short)\n",
    "    comm_s2=abs(price_s2*commission_long if price_s2 > 0 else price_s2*commission_short)\n",
    "    return comm_s1+comm_s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trade_sheet(buy,sell,status,data,coint,commission_short=0,commission_long=0):\n",
    "    #To equal the dates and spread\n",
    "\n",
    "    dates=data['Date'].values\n",
    "    s1=data['ydata'].values\n",
    "    s2=data['xdata'].values\n",
    "    trade_ticket=pd.DataFrame()\n",
    "    net_profit=np.zeros(len(buy),dtype=np.float)\n",
    "    gross_profit=np.zeros(len(buy),dtype=np.float)\n",
    "    duration=np.zeros(len(buy),dtype=np.float)\n",
    "    buy_price=np.zeros(len(buy),dtype=np.float)\n",
    "    sell_price=np.zeros(len(buy),dtype=np.float)\n",
    "    margin=np.zeros(len(buy),dtype=np.float)\n",
    "    flag=0\n",
    "    \n",
    "    buy_date=[]\n",
    "    sell_date=[]\n",
    "    stat=[]\n",
    "    \n",
    "    if len(buy) == len(sell):\n",
    "        tot=len(buy)\n",
    "    else:\n",
    "        tot=len(buy)-1\n",
    "        flag=1\n",
    "\n",
    "  \n",
    "    for i in range(0,tot):\n",
    "         \n",
    "        if status[i] > 0:\n",
    "            buy_weights=np.negative(coint[buy[i]])\n",
    "            sell_weights=np.negative(coint[sell[i]])\n",
    "        else:    \n",
    "            buy_weights=coint[buy[i]]\n",
    "            sell_weights=coint[sell[i]]\n",
    "        \n",
    "        # Computing the buy and selling price of inidvidual asset class\n",
    "        sell_s1=s1[sell[i]]*sell_weights[0]\n",
    "        sell_s2=-s2[sell[i]]*sell_weights[1]\n",
    "        buy_s2=-s2[buy[i]]*buy_weights[1]\n",
    "        buy_s1=s1[buy[i]]*buy_weights[0]\n",
    "        \n",
    "        sell_price[i]=sell_s1+sell_s2\n",
    "        buy_price[i]=buy_s1+buy_s2\n",
    "        sell_cost=commission(sell_s1,sell_s2,commission_short,commission_long)\n",
    "        buy_cost=commission(buy_s1,buy_s2,commission_short,commission_long)\n",
    "        trade_cost=sell_cost+buy_cost\n",
    "        \n",
    "        # Computing the profit and margin, duration  for each trade  \n",
    "        margin[i]=net_profit[i]/(abs(buy_s1)+abs(buy_s2))\n",
    "        gross_profit[i]=sell_price[i]-buy_price[i]\n",
    "        net_profit[i]=gross_profit[i]-trade_cost\n",
    "        duration[i]=sell[i]-buy[i]+1\n",
    "        \n",
    "        buy_date.append(dates[buy[i]])\n",
    "        sell_date.append(dates[sell[i]])\n",
    "        if abs(status[i]) == 1:\n",
    "            stat.append(\"Completed\")\n",
    "        if abs(status[i]) == 2:\n",
    "            stat.append(\"Maximum Time Elapsed\")\n",
    "        if abs(status[i]) == 3:\n",
    "            stat.append(\"Stoploss Breached\")\n",
    "        \n",
    "    \n",
    "    if flag== 1:       \n",
    "        buy_date.append(dates[buy[tot]])\n",
    "        duration[tot]=len(s1)-buy[tot]\n",
    "        stat.append(\"Ongoing\")\n",
    "        sell_date.append(\"NA\")\n",
    "\n",
    "    df=pd.DataFrame({'Buy Date':buy_date,'Buy Price':buy_price,'Sell Date':sell_date,'Sell Price':sell_price,'Duration':duration,'Net Profit':net_profit,'Gross Profit':gross_profit,'Status':stat})\n",
    "        \n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backtesting \n",
    "\n",
    "Backtesting is split into 2 different activities. First step of backtesting is involved with producing trading statistics from the strategy and analysing chracteristics of the trades made. The second activity is involved with analysing the returns generated by the strategy and performing comparitive analysis on those returns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Producing a summary of the strategy\n",
    "\n",
    "The statistics of the strategy including the complete, incomplete, profitable, loss-making trades, the average profitability, duration and ratio of profit to loss trades are reported. A summary for all trades terminated due to the breached stoploss or execeeded time limit are separately generated. \n",
    "A boxplot of the trade duration, profit and return is made. This is done to analyse whether these properties of the trade skewed by a large single trade or they are uniform across all trades in the strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def backtest(df,returns,dates,rfr,display=True,window=125):\n",
    "    \n",
    "    #Trade Statistics\n",
    "    flag=0\n",
    "    try:\n",
    "    \n",
    "            # Preparing Dataframe of returns for computing Sharpe Ratio\n",
    "            df_ret=pd.DataFrame(returns)\n",
    "            df_ret.columns=['Returns']\n",
    "            df_ret['Date']=dates[-df_ret.shape[0]:].values\n",
    "            df_returns=df_ret.drop(df_ret[df_ret['Returns'] == 0].index,axis=0)\n",
    "            dates_of_trading = pd.DataFrame(df_returns['Date'],columns=['Date'])\n",
    "            df_rets=pd.DataFrame(df_returns['Date'],columns=['Date'])\n",
    "            df_rets['Returns']=df_returns['Returns']\n",
    "            df_returns['Returns+1']=df_returns['Returns']+1\n",
    "            df_returns['Rf_Returns']=df_returns['Returns']-((rfr+1)**(float(1)/252)-1)\n",
    "        \n",
    "\n",
    "            #Finding Fama French 4 Factors\n",
    "            ff=pd.read_csv('FourFactors.csv',parse_dates=[0],usecols=['Date','HML %','SMB %','WML %','Rm-Rf %'])\n",
    "            ff.dropna(inplace=True)\n",
    "            ff_comb=dates_of_trading.merge(ff,on='Date')\n",
    "            ff=dates_of_trading.merge(ff,on='Date')\n",
    "            ff.set_index(ff['Date'],inplace=True)\n",
    "            ff.drop('Date',axis=1,inplace=True)\n",
    "            ff_comb.drop('Date',axis=1,inplace=True)\n",
    "            ff_comb=ff_comb/100\n",
    "            ff=ff/100  \n",
    "            beta_ff,alpha_ff,na=regression(ff_comb,df_returns['Rf_Returns'])\n",
    "            \n",
    "            # Finding market alpha and beta\n",
    "            beta_m,alpha_m,na=regression(ff_comb['Rm-Rf %'],df_returns['Rf_Returns'])\n",
    "            \n",
    "            total_trades=df.shape[0]\n",
    "            complete_trades = df[df['Status']=='Completed'].shape[0]\n",
    "            incomplete_trades=total_trades-complete_trades  \n",
    "            average_duration=df['Duration'].mean()\n",
    "            average_profit=df['Net Profit'].mean()\n",
    "            total_profit=df['Net Profit'].sum()\n",
    "            profit_trades=df[df['Net Profit']>0].shape[0]\n",
    "            average_profit_profittrades=df[df['Net Profit']>0]['Net Profit'].mean()\n",
    "            risk=np.std(returns)\n",
    "            ret=np.sort(returns)\n",
    "\n",
    "            # Calculating the Value at Risk and Expected Shortfall of the Strategy\n",
    "            dec=0.05*len(returns)%1\n",
    "            i1=int(np.floor(0.05*len(returns))-1)\n",
    "            i2=int(np.ceil(0.05*len(returns))-1)\n",
    "            var=ret[i1]+(ret[i2]-ret[i1])*(dec)\n",
    "            es=np.append(ret[0:i1],(ret[i2]-ret[i1])*(dec)).mean()\n",
    "            loss_trades=total_trades-profit_trades\n",
    "            \n",
    "            # Calculating the Sharpe and Sortino Ratio of the Strategy\n",
    "            cumulative_annualised_return=df_returns['Returns+1'].prod()**(float(252)/len(df_returns))-1\n",
    "            portfolio_sd=df_returns['Returns'].std()*(252**0.5)    \n",
    "            negative_return_sd=df_returns[df_returns['Returns']<0]['Returns'].std()*(252**0.5)\n",
    "            sharpe=(cumulative_annualised_return-rfr)/(portfolio_sd)\n",
    "            sortino=(cumulative_annualised_return-rfr)/(negative_return_sd)\n",
    "            \n",
    "            \n",
    "            if total_trades >0:\n",
    "                strat_summary={'Total Trades':total_trades,'Complete Trades':complete_trades,'Incomplete Trades':incomplete_trades,\n",
    "                   'Profit Trades':profit_trades,'Loss Trades':loss_trades,'Total Profit':total_profit,'Average Profit on Profitable Trades':average_profit_profittrades,'Average Trade Duration':average_duration,\n",
    "                   'Average Profit':average_profit,'Win Ratio':float(profit_trades)/loss_trades,'Standard Deviation of Returns':risk,'Value at Risk':var, 'Expected Shortfall':es,'Sharpe Ratio':sharpe,\n",
    "                    'Sortino Ratio':sortino,'Cumulative Return':cumulative_annualised_return,'Market Alpha':alpha_m,'Market Beta':beta_m,\n",
    "                    'HML Beta':beta_ff[0], 'SMB Beta' :beta_ff[1], 'WML Beta':beta_ff[2], 'Momentum Beta':beta_ff[3],'Fama French Four Factor Alpha':alpha_ff}\n",
    "\n",
    "                if display == True:\n",
    "                    print (\"\\nSummary of all trades made:\")\n",
    "                    for i in strat_summary:\n",
    "                        print (i,':',strat_summary[i])\n",
    "                \n",
    "                    print (\"(All Profits calculations are made using the Net Profits, where the commisions have been deducted from the Profits)\")\n",
    "            else:\n",
    "                flag=1\n",
    "                strat_summary={'Total Trades':0,'Complete Trades':0,'Incomplete Trades':0,\n",
    "                   'Profit Trades':0,'Loss Trades':0,'Total Profit':0,'Average Trade Duration':0,\n",
    "                   'Average Profit':0,'Standard Deviation of Returns':0,'Value at Risk':0, 'Expected Shortfall':0, 'Sharpe Ratio':0,\n",
    "                    'Sortino Ratio':0,'Cumulative Return':0,'Market Alpha':0,'Market Beta':0,'HML Beta':0,\n",
    "                    'SMB Beta':0, 'WML Beta':0, 'Momentum Beta':0,'Fama French Four Factor Alpha':0}\n",
    "                print (\"No trades were executed\")\n",
    "                \n",
    "    except:\n",
    "            flag=1\n",
    "            strat_summary={'Total Trades':0,'Complete Trades':0,'Incomplete Trades':0,\n",
    "                   'Profit Trades':0,'Loss Trades':0,'Total Profit':0,'Average Trade Duration':0,\n",
    "                   'Average Profit':0,'Standard Deviation of Returns':0,'Value at Risk':0, 'Expected Shortfall':0, 'Sharpe Ratio':0,\n",
    "                    'Sortino Ratio':0,'Cumulative Return':0,'Market Alpha':0,'Market Beta':0,'HML Beta':0,\n",
    "                    'SMB Beta':0, 'WML Beta':0, 'Momentum Beta':0,'Fama French Four Factor Alpha':0}\n",
    "            if display == True:\n",
    "                print (\"No trades were executed\")\n",
    "        \n",
    "    \n",
    "        #Time Elapsed Trades\n",
    "    try: \n",
    "        te=df[df['Status']== \"Maximum Time Elapsed\"]\n",
    "        te_trades=te.shape[0]\n",
    "        te_exposure=te['Net Profit'].mean()\n",
    "        te_summary={'Trades':te_trades,'Net Exposure':te_exposure}\n",
    "        if display == True:\n",
    "        \n",
    "            if te_trades == 0:\n",
    "                te_summary={'Trades':0,'Net Exposure':0}\n",
    "                print(\"\\nNo trades that exceeded the maximum duration\")\n",
    "            else:\n",
    "                print (\"\\nSummary of all Time Limit Exceeded trades:\")\n",
    "                for i in te_summary:\n",
    "                        print (i,':',te_summary[i])\n",
    "    except:\n",
    "        te_summary={'Trades':0,'Net Exposure':0}\n",
    "        if display == True:\n",
    "            print(\"\\nNo trades that exceeded the maximum duration\")\n",
    "    \n",
    "    #Stoploss Breached Trades \n",
    "    try: \n",
    "        slb=df[df['Status']=='Stoploss Breached']\n",
    "        slb_trades=slb.shape[0]\n",
    "        slb_average_duration=slb['Duration'].mean()\n",
    "        slb_average_loss=-1*slb['Net Profit'].mean()\n",
    "        slb_summary={'Trades':slb_trades,'Average Duration':slb_average_duration,\n",
    "                   'Average Loss':slb_average_loss}\n",
    "        if display == True:\n",
    "            if slb_trades == 0:\n",
    "                print(\"\\nNo trades that breached the stoploss\")\n",
    "                slb_summary={'Trades':0,'Average Duration':0,\n",
    "                   'Average Loss':0}\n",
    "            else:\n",
    "                print (\"\\nSummary of all Stoploss Breached trades:\")\n",
    "                for i in slb_summary:\n",
    "                    print (i,':',slb_summary[i])\n",
    "    except:\n",
    "        if display == True:\n",
    "            print(\"\\nNo trades that breached the stoploss\")\n",
    "        slb_summary={'Trades':0,'Average Duration':0,\n",
    "                   'Average Loss':0}\n",
    "    \n",
    "    if display == True:\n",
    "            \n",
    "        if flag == 0:\n",
    "            plt.figure(figsize=(15,10))\n",
    "            plt.subplot(131)\n",
    "            \n",
    "            plt.boxplot(df['Duration'])\n",
    "            plt.xlabel('Duration')\n",
    "            plt.ylabel('Number of Trading sessions')\n",
    "            plt.title('Duration of all trades')\n",
    "    \n",
    "            \n",
    "            plt.subplot(132)\n",
    "            plt.boxplot(df['Net Profit'])\n",
    "            plt.xlabel('Profit')\n",
    "            plt.ylabel('Profit in $''s')\n",
    "            plt.title('Profit of all trades')\n",
    "    \n",
    "            plt.subplot(133)\n",
    "            plt.boxplot(returns)\n",
    "            plt.xlabel('Returns')\n",
    "            plt.ylabel('Returns in %')\n",
    "            plt.title('Returns of all trades')\n",
    "            plt.show()\n",
    "            \n",
    "            #Rolling Sharpe Ratio\n",
    "            print( \"\\n The rolling Sharpe Ratio is: \")\n",
    "            rolling_returns=((df_returns['Returns+1'].rolling(window).apply(lambda x:x.prod()))**(float(252)/window))-1\n",
    "            rolling_sharpe = (rolling_returns-rfr)/(df_returns['Returns'].rolling(window).std()*(252**0.5))\n",
    "            rolling_sharpe.dropna(inplace=True)\n",
    "            plt.figure(figsize=(10,10))\n",
    "            plt.plot(rolling_sharpe,label=\"Rolling Sharpe\")\n",
    "            plt.xlabel('Trading Sessions')\n",
    "            plt.ylabel('Sharpe Ratio')\n",
    "            plt.title('Rolling Annual Sharpe Ratio')\n",
    "            plt.legend()\n",
    "            plt.show()    \n",
    "          \n",
    "            print (\"\\n The rolling Alpha, Beta factors on the market are: \")\n",
    "            rolling_beta=[]\n",
    "            rolling_alpha=[]\n",
    "            \n",
    "            for i in range(0,df_returns.shape[0]-window):\n",
    "                am,bm,na=regression(ff_comb[i:i+window]['Rm-Rf %'],df_returns[i:i+window]['Rf_Returns'])\n",
    "                rolling_beta.append(am)\n",
    "                rolling_alpha.append(bm)\n",
    "\n",
    "            plt.figure(figsize=(24,10))\n",
    "            plt.subplot(121)\n",
    "            plt.plot(rolling_alpha,label='Rolling Alpha')\n",
    "            plt.xlabel('Trading Sessions')\n",
    "            plt.ylabel('Alpha')\n",
    "            plt.title('6M Rolling Market Alpha')\n",
    "            plt.legend()\n",
    "            plt.subplot(122)\n",
    "            plt.plot(rolling_beta,label='Rolling Beta')\n",
    "            plt.xlabel('Trading Sessions')\n",
    "            plt.ylabel('Beta')\n",
    "            plt.title('6M Rolling Market Beta')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "            \n",
    "            # Rolling Fama-French Factors      \n",
    "            rolling_alpha_ff=[]\n",
    "            rolling_beta_hml=[]\n",
    "            rolling_beta_smb=[]\n",
    "            rolling_beta_wml=[]\n",
    "            rolling_beta_mom=[]\n",
    "    \n",
    "            for i in range(0,df_returns.shape[0]-window):\n",
    "                a,b,resid1=regression(ff_comb[i:i+window],df_returns[i:i+window]['Rf_Returns'])\n",
    "                rolling_beta_hml.append(a[0])\n",
    "                rolling_beta_smb.append(a[1])\n",
    "                rolling_beta_wml.append(a[2])\n",
    "                rolling_beta_mom.append(a[3])\n",
    "                rolling_alpha_ff.append(b)\n",
    "            plt.figure(figsize=(24,10))\n",
    "            plt.subplot(121)\n",
    "            plt.plot(rolling_beta_hml,label='Rolling Beta HML')\n",
    "            plt.plot(rolling_beta_smb,label='Rolling Beta SMB')\n",
    "            plt.plot(rolling_beta_wml,label='Rolling Beta WML')\n",
    "            plt.plot(rolling_beta_mom,label='Rolling Beta MoM')\n",
    "            plt.xlabel('Trading Sessions')\n",
    "            plt.ylabel('Beta')\n",
    "            plt.title('6M Rolling Beta of the 4 Factor model')\n",
    "            plt.legend()\n",
    "            plt.subplot(122)\n",
    "            plt.plot(rolling_alpha_ff,label='Rolling Alpha')\n",
    "            plt.xlabel('Trading Sessions')\n",
    "            plt.ylabel('Alpha')\n",
    "            plt.title('6M Rolling Alpha from the 4 Factor model')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "\n",
    "            # Producing tear sheet from returns \n",
    "            df_rets['Date']=pd.to_datetime(df_rets['Date'])\n",
    "            df_rets.set_index(df_rets['Date'],inplace=True)\n",
    "     \n",
    "            pf.create_full_tear_sheet(df_rets['Returns'],benchmark_rets=ff['Rm-Rf %'],factor_returns=ff)\n",
    "\n",
    "\n",
    "        \n",
    "    return strat_summary,te_summary,slb_summary\n",
    "    \n",
    "   \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysing the returns of the strategy\n",
    "\n",
    "The Sharpe and Sortino Ratio, the alpha and beta of the strategy based on the market factor and the Fama French factors are computed. The rolling Sharpe ratio is also calculated for a monthly time interval. \n",
    "\n",
    "A Quantopian tear sheet is implemented from the 'Pyfolio' library. The tear sheet includes industry level advanced analysis on the returns including drawdowns in the strategy and computed the rolling alpha and beta for the market strategy. Advanced returns components like skew and kurtosis, VaR are calculated. \n",
    "\n",
    "The tear sheet analyses both trade simulations in the backtesting period and the live trading period. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trading System \n",
    "\n",
    "The cointegration system is implemented and a final algorithm is outlined which an end user can use to test and trade on a strategy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trading_algorithm():\n",
    "    print (\"Input the 2 asset classes for cointegration\")\n",
    "    name1=input(\"Input the first asset class for cointegration: \")\n",
    "    name2=input(\"Input the second asset class for cointegration: \")\n",
    "\n",
    "    asset1=pd.read_csv('data/{}.csv'.format(name1),usecols=['Date','Adj Close'],parse_dates=[0])\n",
    "    asset2=pd.read_csv('data/{}.csv'.format(name2),usecols=['Date','Adj Close'],parse_dates=[0])\n",
    "    pair=pd.merge(asset1,asset2,how='inner',on=['Date'])\n",
    "    pair.columns=['Date','ydata','xdata']\n",
    "    pair.dropna(inplace=True)\n",
    "\n",
    "    \n",
    "    start=pd.to_datetime(input(\"Enter the start date to run cointegration test: \"))\n",
    "    end=pd.to_datetime(input(\"Enter the end date to run cointegration test: \"))\n",
    "    pairs_training=pair[pair['Date'] > start]\n",
    "    pairs_training=pairs_training[pairs_training['Date'] < end]\n",
    "    \n",
    "    adf_ci=float(input(\"Enter the confidence interval for the ADF test: \"))\n",
    "    sig_test_ci=float(input(\"Enter the confidence interval for the cointegration significance test: \"))\n",
    "    \n",
    "    flag3=cointegration_test(pairs_training['xdata'],pairs_training['ydata'],adf_ci,sig_test_ci,name1,name2,)\n",
    "    if flag3 == 2:\n",
    "            pairs_training.columns=['Date','xdata','ydata']\n",
    "            pair.columns=['Date','xdata','ydata']\n",
    "            temp=name1\n",
    "            name1=name2\n",
    "            name2=temp\n",
    "\n",
    "    if  flag3==1 or flag3==2: \n",
    "        print (\"\\nEnter a larger date range to asses the robustness of the cointegration\")\n",
    "        date1=pd.to_datetime(input('Start Date: '))\n",
    "        date2=pd.to_datetime(input('End Date: '))\n",
    "        rob_ci=float(input(\"Enter a confidence interval for robustness test: \"))\n",
    "        robust_set=pair[pair['Date'] > date1]\n",
    "        robust_set=robust_set[robust_set['Date'] < date2]\n",
    "        robustness(pairs_training['xdata'],pairs_training['ydata'],robust_set['xdata'],robust_set['ydata'],rob_ci)\n",
    "        \n",
    "        print(\"------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\")\n",
    "        #\n",
    "        if int(input(\"\\nContinue with strategy fitting on training data: Yes-1, No-0: \")) == 1:\n",
    "            flag1=int(input(\"Calculate residuals using Kalman Filters-1 or Linear Regression-0: \"))\n",
    "            flag2=int(input(\"Calculate Ornstein Uhlenbeck parameters using Kalman Filters-1 or Linear Regression-0: \"))\n",
    "            \n",
    "            if flag1 == 1:\n",
    "                delta_r=float(input(\"Enter Delta value for Kalman Filter for computing Cointegration Weight. Default is 0.0001: \"))\n",
    "                coef_tr,intercept_tr,spread_tr=dynamic_regression(pairs_training['xdata'],pairs_training['ydata'],delta_r)\n",
    "                \n",
    "            else:\n",
    "                coef_tr,intercept_tr,spread_tr=regression(pairs_training['xdata'],pairs_training['ydata'])\n",
    "            \n",
    "            \n",
    "            print(\"------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\")\n",
    "            print(\"\\nThe cointegration weights and the intercept for the trading strategy are as follows: \\n\")\n",
    "            if flag1 == 0:\n",
    "                print (\"{}:{}\".format(name1,1))\n",
    "                print (\"{}:{}\".format(name2,coef_tr))\n",
    "                print (\"Intercept: {}\".format(intercept_tr))\n",
    "            else:\n",
    "                print (\"{}:{}\".format(name1,1))\n",
    "                plt.figure(figsize=(24,10))\n",
    "                plt.subplot(121)\n",
    "                plt.plot(coef_tr,label='Cointegration Weight {}'.format(name2))\n",
    "                plt.title('Estimate of Cointegration Weight of {}'.format(name2))\n",
    "                plt.ylabel('Weight')\n",
    "                plt.xlabel('Trading Sessions')\n",
    "                plt.legend()\n",
    "                plt.subplot(122)\n",
    "                plt.plot(intercept_tr,label='Regression Intercept')\n",
    "                plt.ylabel('Intercept')\n",
    "                plt.title('Estimate of Cointegration Intercept')\n",
    "                plt.xlabel('Trading Sessions')\n",
    "                plt.legend()\n",
    "                plt.show()\n",
    "                \n",
    "            print(\"------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\")\n",
    "            if flag2 == 1:\n",
    "                delta_ou=float(input(\"Enter Delta value for Kalman Filter for fitting to OU process. Default is 0.0001: \"))\n",
    "                mean_tr,diffeq_tr=build_strategy(spread_tr,True,delta_ou)\n",
    "            else:\n",
    "                mean_tr,diffeq_tr=build_strategy(spread_tr)\n",
    "            \n",
    "            if flag1 == 1:\n",
    "                coef_tr=coef_tr[-len(mean_tr):]\n",
    "            else:\n",
    "                coef_tr=np.repeat(coef_tr,len(mean_tr))\n",
    "            \n",
    "            spread_tr=spread_tr[-len(mean_tr):]\n",
    "            pairs_tr=pairs_training[-len(mean_tr):]\n",
    "            coint_tr=np.vstack([np.ones(len(coef_tr)),coef_tr]).T\n",
    "            print(\"------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\")\n",
    "            #\n",
    "            if int(input(\"\\nSimulate trading on training data using the fitted parameters: Yes-1, No-0: \")) ==1:\n",
    "                print (\"Enter the Following trading parameters:\")\n",
    "                entry_point=float(input(\"Number of standard deviations from the mean at which trade should be initiated: \"))\n",
    "                slippage=float(input(\"The permissible slippage observed on residual spread: [Enter -999 for no slippage consideration]: \"))\n",
    "                stoploss=float(input(\"The permissible stoploss observed on residual spread: [Enter -999 for no stoploss consideration]: \"))\n",
    "                comm_short=float(input(\"The commission on executing a short trade: [Enter 0 for no commission consideration]: \"))\n",
    "                comm_long=float(input(\"The commission on executing a long trade: [Enter 0 for no commission consideration]: \"))\n",
    "                rfr=float(input(\"Risk free rate: \"))\n",
    "                max_trade_exit=int(input(\"Maximum number of days a trade can last post the trade initiation: [Enter -999 for no maximum trade duration consideration]: \"))\n",
    "                print(\"------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\")\n",
    "                print (\"\\n The trading strategy on the training period is \\n\")\n",
    "                #\n",
    "                buy_tr,sell_tr,status_tr,portfolio_value_tr,returns_tr=trade(pairs_tr,spread_tr,mean_tr,diffeq_tr,coef_tr,entry_point,slippage,rfr,max_trade_exit,stoploss)\n",
    "                trade_ticket_tr=trade_sheet(buy_tr,sell_tr,status_tr,pairs_tr,coint_tr,comm_short,comm_long)\n",
    "                print (\"Details of Trades executed: \")\n",
    "                print (trade_ticket_tr)\n",
    "                print(\"------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\")\n",
    "                if int(input(\"\\nPrint backtesting analysis of trading on training data : Yes-1, No-0:\")) ==1:\n",
    "                #if 1==1:\n",
    "                    pairs_tr=pairs_tr[-len(returns_tr):]\n",
    "                    backtest(trade_ticket_tr,returns_tr,pairs_tr['Date'],rfr)\n",
    "                    \n",
    "                print(\"------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\")\n",
    "                if input(\"\\nCompute Optimized parameters for the training spread: Yes-1, No-0: \") == 1:  \n",
    "                                        \n",
    "                    if flag1 == 1 and flag2 ==1: \n",
    "                        if int(input(\"\\nOptimise over delta parameter in the transition covariance matrix in Kalman Filter for both computing cointegration weight and fitting to OU process: Yes-1, No-0: \")) == 1:\n",
    "                            opt_delta_resid,opt_delta_mr=optimize_delta(pairs_training,spread_tr,entry_point,pairs_tr['Date'],coef_tr,slippage,rfr,max_trade_exit,stoploss,comm_short,comm_long,5)\n",
    "                            coef_tr,intercept_tr,spread_tr=dynamic_regression(pairs_training['xdata'],pairs_training['ydata'],opt_delta_resid) \n",
    "                            mean_tr,diffeq_tr=build_strategy(spread_tr,True,opt_delta_mr,False)\n",
    "                            coef_tr=coef_tr[-len(mean_tr):]\n",
    "                            spread_tr=spread_tr[-len(mean_tr):]\n",
    "                            intercept_tr=intercept_tr[-len(mean_tr):]\n",
    "                        else:\n",
    "                            opt_delta_resid,opt_delta_mr=delta_r,delta_ou\n",
    "                                  \n",
    "                    elif flag1 == 1:\n",
    "                        if int(input(\"\\nOptimise over delta parameter in the transition covariance matrix in Kalman Filter for computing cointegration weight: Yes-1, No-0: \")) == 1:\n",
    "                            if flag2 == 1:\n",
    "                                opt_delta_resid=optimize_delta(pairs_training,spread_tr,entry_point,pairs_tr['Date'],coef_tr,slippage,rfr,max_trade_exit,stoploss,comm_short,comm_long,4,delta_ou)\n",
    "                                coef_tr,intercept_tr,spread_tr=dynamic_regression(pairs_training['xdata'],pairs_training['ydata'],opt_delta_resid)\n",
    "                                mean_tr,diffeq_tr=build_strategy(spread_tr,True,delta_ou,False)\n",
    "                                \n",
    "                            else:\n",
    "                                opt_delta_resid=optimize_delta(pairs_training,spread_tr,entry_point,pairs_tr['Date'],coef_tr,slippage,rfr,max_trade_exit,stoploss,comm_short,comm_long,2)\n",
    "                                coef_tr,intercept_tr,spread_tr=dynamic_regression(pairs_training['xdata'],pairs_training['ydata'],opt_delta_resid)\n",
    "                                mean_tr,diffeq_tr=build_strategy(spread_tr,display=False)\n",
    "                                \n",
    "                            spread_tr=spread_tr[-len(mean_tr):]\n",
    "                            coef_tr=coef_tr[-len(mean_tr):]\n",
    "                            intercept_tr=intercept_tr[-len(mean_tr):]\n",
    "                        else:\n",
    "                            opt_delta_resid=delta_r\n",
    "                        \n",
    "                        \n",
    "                    elif flag2 == 1:\n",
    "                        if int(input(\"\\nOptimise over delta parameter in the transition covariance matrix in Kalman Filter for fitting to OU process: Yes-1, No-0: \")) == 1:\n",
    "                        #if 1==1:    \n",
    "                            opt_delta_mr=optimize_delta(pairs_training,spread_tr,entry_point,pairs_tr['Date'],coef_tr,slippage,rfr,max_trade_exit,stoploss,comm_short,comm_long,3)\n",
    "                            mean_tr,diffeq_tr=build_strategy(spread_tr,True,opt_delta_mr,False)\n",
    "                        else:\n",
    "                            opt_delta_mr=delta_ou\n",
    "                        spread_tr=spread_tr[-len(mean_tr):]\n",
    "                        coef_tr=coef_tr[-len(mean_tr):]\n",
    "                            \n",
    "                    \n",
    "                    if int(input(\"\\nOptimise over Entry Bound, Slippage, Maximum trade duration, Stoploss: Yes-1, No-0: \")) == 1:\n",
    "                    #if 1==1:\n",
    "                        opt_entry_point,opt_slippage,opt_max_trade_exit,opt_stoploss=optimize(pairs_tr,spread_tr,mean_tr,diffeq_tr,entry_point,pairs_tr['Date'],coint_tr,slippage,rfr,max_trade_exit,stoploss,comm_short,comm_long)\n",
    "                        \n",
    "                    else:\n",
    "                        opt_entry_point,opt_slippage,opt_max_trade_exit,opt_stoploss=entry_point,slippage,max_trade_exit,stoploss\n",
    "\n",
    "\n",
    "            print(\"------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\")\n",
    "            \n",
    "            if int(input(\"\\nPerform Testing: Yes-1, No-0: \")) ==1:\n",
    "                start=pd.to_datetime(input('Start Date: '))\n",
    "                end=pd.to_datetime(input('End Date: '))\n",
    "                pairs_testing=pair[pair['Date'] > start]\n",
    "                pairs_testing=pairs_testing[pairs_testing['Date'] < end]\n",
    "                pairs_te=pairs_testing\n",
    "        \n",
    "                ''' When Kalman Filters are used using live trading, the cointegration weights are rebalanced\n",
    "                daily. To implement this we compute the coefficient and intercept for all trading session and \n",
    "                then shift it one day forward, so that for the current trading session, the cointegrating\n",
    "                weights are computed from the entire data before the trading sesion. '''\n",
    "                \n",
    "                flag4=int(input('Use optimized parameters-1, Use training parameters-2, Enter new trading parameters-3: '))\n",
    "                if flag4 !=2 and flag4 != 3:\n",
    "                    flag4=1\n",
    "                    \n",
    "                if flag1 == 1:\n",
    "                    if flag4 == 1:\n",
    "                        delta_r=opt_delta_resid\n",
    "                    if flag4 ==3:\n",
    "                        delta_r=float(input(\"Delta value for Kalman Filter for computing Cointegration Weight. Default is 0.0001: \"))\n",
    "                    \n",
    "                    coef_te,intercept_te,spread_te=dynamic_regression(pairs_testing['xdata'],pairs_testing['ydata'],delta_r)                \n",
    "                    coef_te=coef_te[:-1]\n",
    "                    intercept_te=intercept_te[:-1]\n",
    "                    pairs_te=pairs_te[1:]\n",
    "                    spread_te=pairs_te['ydata']-coef_te*pairs_te['xdata']-intercept_te\n",
    "                    spread_te=spread_te.values\n",
    "                    plt.figure(figsize=(24,10))\n",
    "                    plt.subplot(121)\n",
    "                    plt.plot(coef_tr,label='Cointegration Weight {}'.format(name2))\n",
    "                    plt.title('Estimate of Cointegration Weight of {}'.format(name2))\n",
    "                    plt.ylabel('Weight')\n",
    "                    plt.xlabel('Trading Sessions')\n",
    "                    plt.legend()\n",
    "                    plt.subplot(122)\n",
    "                    plt.plot(intercept_tr,label='Regression Intercept')\n",
    "                    plt.ylabel('Intercept')\n",
    "                    plt.title('Estimate of Cointegration Intercept')\n",
    "                    plt.xlabel('Trading Sessions')\n",
    "                    plt.legend()\n",
    "                    plt.show()\n",
    "\n",
    "                    \n",
    "                else:\n",
    "                    coef_te=coef_tr[0]\n",
    "                    intercept_te=intercept_tr\n",
    "                    spread_te=pairs_te['ydata']-coef_te*pairs_te['xdata']-intercept_te\n",
    "                    spread_te=spread_te.values\n",
    "                \n",
    "\n",
    "                if flag2 == 1:\n",
    "                    if flag4 == 1:\n",
    "                        delta_ou=opt_delta_mr\n",
    "                    if flag4 ==3:\n",
    "                        delta_ou=float(input(\"Delta value for Kalman Filter for fitting to OU process. Default is 0.0001: \"))\n",
    "                    mean_te,diffeq_te=build_strategy(spread_te,True,delta_ou,True)\n",
    "\n",
    "                else:\n",
    "                    mean_te=np.repeat(mean_tr[0],pairs_te.shape[0])\n",
    "                    diffeq_te=np.repeat(diffeq_tr[0],pairs_te.shape[0])                \n",
    "        \n",
    "                if flag1 == 1:\n",
    "                    coef_te=coef_te[-len(mean_te):]\n",
    "                else:\n",
    "                    coef_te=np.repeat(coef_te,len(mean_te))\n",
    "                    \n",
    "                spread_te=spread_te[-len(mean_te):]\n",
    "                coef_te=coef_te[-len(mean_te):]\n",
    "                pairs_te=pairs_te[-len(mean_te):]\n",
    "                coint_te=np.vstack([np.ones(len(coef_te)),coef_te]).T\n",
    "    \n",
    "                if flag4 == 1:\n",
    "                    entry_point=opt_entry_point\n",
    "                    slippage=opt_slippage\n",
    "                    max_trade_exit=opt_max_trade_exit\n",
    "                    stoploss=opt_stoploss\n",
    "                        \n",
    "                if flag4 == 3:\n",
    "                    print (\"\\nEnter the Following trading parameters: \")\n",
    "                    entry_point=float(input(\"Number of standard deviations from the mean at which trade should be initiated: \"))\n",
    "                    slippage=float(input(\"The permissible slippage observed on residual spread: \"))\n",
    "                    max_trade_exit=int(input(\"Maximum number of days a trade can last post the trade initiation: \"))\n",
    "                    stoploss=float(input(\"The permissible stoploss observed on the residual spread: \"))\n",
    "                print(\"------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\")\n",
    "                print (\"\\n The trading strategy on the testing period is \\n\")\n",
    "                \n",
    "                \n",
    "                buy_te,sell_te,status_te,portfolio_value_te,returns_te=trade(pairs_te,spread_te,mean_te,diffeq_te,coef_te,entry_point,slippage,rfr,max_trade_exit,stoploss)\n",
    "                trade_ticket_te=trade_sheet(buy_te,sell_te,status_te,pairs_te,coint_te,comm_short,comm_long)\n",
    "                print (\"\\nDetails of Trades executed: \")\n",
    "                print (trade_ticket_te)\n",
    "                print(\"------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\")\n",
    "                print (\"\\n\\nAnalysis of performance of trading on testing data: \")                     \n",
    "                backtest(trade_ticket_te,returns_te,pairs_te['Date'],rfr)\n",
    "                \n",
    "            else:\n",
    "                print(\"------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\")\n",
    "                print (\"\\nNo testing performed. The program is terminated\")\n",
    "        else:\n",
    "            print(\"------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\")\n",
    "            print (\"\\nNo simulation of trading on training or testing analysis performed. The program is terminated\")\n",
    "    else:\n",
    "        print(\"------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\")\n",
    "        print (\"\\nNo pairs trading statistical arbitrage strategy exists for this pair. The program is terminated \")\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing of cointegration pair: GODREJCP.NS & LT.NS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Strategy implemented with linear regression for both residual calculation and fitting to OU process\n",
    "trading_algorithm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategy implemented with linear regression for residual calculation and Kalman Filters for fitting to OU process\n",
    "trading_algorithm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategy implemented with use of Kalman Filters for residual calculation and linear regression for fitting to OU process\n",
    "trading_algorithm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategy implemented with use of Kalman Filters for both residual calculation and fitting to OU processtrading_algorithm()\n",
    "trading_algorithm()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing of cointegration pair: AXISBANK.NS & M&M.NS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategy implemented with use of Kalman Filters for residual calculation and linear regression for fitting to OU process\n",
    "trading_algorithm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Strategy implemented with use of Kalman Filters for residual calculation and linear regression for fitting to OU process\n",
    "trading_algorithm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategy implemented with linear regression for both residual calculation and fitting to OU process\n",
    "trading_algorithm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategy implemented with use of Kalman Filters for both residual calculation and fitting to OU process\n",
    "trading_algorithm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategy implemented with linear regression for residual calculation and Kalman Filters for fitting to OU process\n",
    "trading_algorithm()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing of cointegration pair: ULTRACEMCO.NS & SHREECEM.NS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategy implemented with use of Kalman Filters for both residual calculation and fitting to OU process\n",
    "trading_algorithm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategy implemented with linear regression for both residual calculation and fitting to OU process\n",
    "trading_algorithm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategy implemented with linear regression for residual calculation and Kalman Filters for fitting to OU process\n",
    "trading_algorithm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategy implemented with use of Kalman Filters for residual calculation and linear regression for fitting to OU process\n",
    "trading_algorithm()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing of cointegration pair: UPL.NS & PGHH.NS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Strategy implemented with linear regression for residual calculation and Kalman Filters for fitting to OU process\n",
    "trading_algorithm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Strategy implemented with linear regression for both residual calculation and fitting to OU process\n",
    "trading_algorithm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategy implemented with use of Kalman Filters for residual calculation and linear regression for fitting to OU process\n",
    "trading_algorithm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Strategy implemented with use of Kalman Filters for both residual calculation and fitting to OU processtrading_algorithm()\n",
    "trading_algorithm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
